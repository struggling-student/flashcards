# Federated Learning and Advanced FL Techniques

## What is Federated Learning and how does it benefit IoT environments?

Federated Learning (FL) is a decentralized machine learning approach where multiple devices collaboratively train a shared model while keeping all the training data local. This technique is particularly beneficial for IoT (Internet of Things) environments, which consist of numerous resource-constrained devices generating sensitive data.

Key benefits for IoT include:
- **Privacy Preservation**: Devices never share raw data; instead, they share only model updates (like gradients or weights), reducing the risk of data leakage.
- **Reduced Latency**: On-device inference allows real-time decision-making without needing to send data to a central server.
- **Lower Communication Costs**: Instead of continuously sending data, devices only periodically share small model updates.
- **Enhanced Scalability and Fault Tolerance**: IoT networks are often composed of many heterogeneous nodes; FL can accommodate diverse capabilities and intermittent connectivity.

## How does Federated Learning compare to traditional centralized and distributed learning?

- **Centralized Learning**: Involves aggregating all data on a central server for model training. This can raise privacy and bandwidth concerns, particularly in IoT settings.
- **Distributed Learning**: Distributes model training across multiple nodes (typically powerful servers), but still assumes data is centrally available and evenly distributed.
- **Federated Learning**: Data remains distributed on the nodes themselves (e.g., mobile or IoT devices). Each device trains locally, then shares its model updates, which are aggregated to improve a global model.

FL enables collaborative learning across devices while addressing privacy, bandwidth, and computation constraints.

## What are the main challenges of Federated Learning in IoT systems?

Some notable challenges include:
- **Non-IID data distributions**: Data across devices is not independent or identically distributed, leading to bias in local models and difficulty in aggregating them.
- **Device heterogeneity**: IoT devices vary significantly in terms of compute, memory, and energy, affecting their ability to participate equally.
- **Unreliable connectivity**: Devices may go offline or have poor network conditions, making participation inconsistent.
- **Security threats**: Devices might be compromised, leading to poisoned updates or leakage of sensitive information through model inversion attacks.
- **Communication bottlenecks**: Frequent exchange of model updates can overload networks with limited bandwidth.

## What is the FedAvg algorithm and how does it work?

FedAvg (Federated Averaging) is a foundational algorithm in Federated Learning introduced in 2017. It works as follows:
1. A subset of client devices is selected for training in each round.
2. Each selected device performs several steps of gradient descent on its local data and computes an updated model.
3. These updated models are sent to a central server.
4. The server performs a weighted average of all received model parameters, proportionally to the size of each client’s dataset.
5. The aggregated model is redistributed to clients for the next round.

This reduces communication by allowing multiple local steps before model exchange and helps improve performance even with non-IID data.

## What distinguishes Decentralised Federated Learning from Centralised FL?

- **Centralised FL** relies on a central server to coordinate training, aggregate updates, and redistribute the global model. It is simple but introduces a single point of failure and privacy concerns.
- **Decentralised FL** eliminates the central server. Devices (or parties) communicate directly with one another using a peer-to-peer protocol. Each device maintains a mixing matrix to control how much influence its neighbors have in parameter aggregation.

Decentralised FL improves resilience and decentralization but introduces complexity in communication topology, convergence analysis, and synchronization.

## What is FedZero and how does it optimize resource use?

FedZero is a Federated Learning framework designed to minimize carbon emissions and optimize energy use while maintaining fairness. It involves:
- **Client Registration**: Devices declare their energy efficiency, maximum computing power, and affiliation to a power domain (group with shared renewable energy).
- **Forecast-based Selection**: Clients are selected based on predicted energy surplus and computing capacity.
- **Fairness Mechanism**: Clients are temporarily blacklisted after being selected to prevent dominance and promote diversity.
- **Objective**: Select the most appropriate clients and training round duration to maximize training effectiveness while adhering to energy constraints.

FedZero is ideal for green and resource-constrained FL deployments.

## How does ProxyFL preserve data privacy in FL?

ProxyFL introduces a dual-model approach:
- **Private Model**: Remains on the device, never shared. It is used for inference.
- **Proxy Model**: A smaller model trained using differentially private mechanisms. Only this model’s parameters are shared with peers.

Each client:
1. Trains both models locally.
2. Exchanges proxy model parameters with neighbors.
3. Updates private model using a loss function that incorporates knowledge from the proxy.

Differential Privacy is ensured by:
- Gradient clipping to limit sensitivity.
- Adding Gaussian noise to gradients (DP-SGD).
This setup ensures that shared data does not expose sensitive information and provides privacy guarantees even under adversarial conditions.

## What is the role of KL Divergence in ProxyFL?

In ProxyFL, KL (Kullback–Leibler) divergence measures how different the output distributions of the private and proxy models are. It plays a central role in the loss function used to align both models:
- The private model's loss includes a component that encourages it to match the behavior of the proxy model (KL divergence from private to proxy).
- The proxy model also includes a KL term to align with the private model’s predictions.

This mutual alignment helps ensure that private knowledge is effectively transferred into the proxy model and vice versa without compromising privacy.

## What are the key privacy guarantees offered by Differential Privacy in FL?

Differential Privacy (DP) provides a formal guarantee that the output of a function (e.g., model parameters or gradients) does not change significantly when any single data point is added or removed from the dataset. In FL:
- **ε (epsilon)** controls privacy loss (lower means better privacy).
- **δ (delta)** bounds the probability of large deviations.

Using DP-SGD in FL:
- Gradients are clipped to bound their norm.
- Noise is added to obscure individual contributions.
- This protects against model inversion and reconstruction attacks, ensuring that an attacker cannot infer sensitive information from the shared updates.

## How does client selection in Federated Learning impact model performance and energy efficiency?

Client selection determines which devices participate in each training round. In IoT scenarios, careful selection is crucial due to:
- **Energy Constraints**: Selecting energy-efficient devices reduces the carbon footprint.
- **System Heterogeneity**: Some devices may be faster or have more reliable connectivity; others may cause delays.
- **Data Representativeness**: Selecting clients with diverse and representative data can help prevent bias in the global model.
Advanced schemes like **FedZero** optimize client selection by forecasting energy availability and enforcing fairness through blacklisting previously chosen clients, ensuring sustainable and balanced participation.

## Why is Differential Privacy particularly important in Federated Learning?

In FL, devices do not share data directly but only model updates. However, even these updates can potentially be exploited to reconstruct private information. Differential Privacy (DP) ensures:
- **Formal Privacy Guarantees**: Limits the impact of any single data point on the output.
- **Resilience to Attacks**: Protects against model inversion, membership inference, and gradient leakage attacks.
- **Compliance with Regulations**: Facilitates adherence to data protection laws like GDPR.
In practice, DP is enforced using techniques like gradient clipping and adding Gaussian noise, as seen in ProxyFL’s implementation.

## What is the structure of a ProxyFL client and how are its models updated?

Each ProxyFL client maintains:
1. A **Private Model** (used for inference, never shared).
2. A **Proxy Model** (shared with neighbors using DP).

Training consists of:
- **Local Updates**: Both models are trained with local data.
- **Exchange Phase**: Proxy models are shared among neighbors.
- **Alignment**: The private model incorporates knowledge from the proxy via a loss function that includes a KL divergence term.
This dual-model architecture allows secure knowledge sharing while ensuring privacy.

## How does KL divergence facilitate model alignment in dual-model FL architectures like ProxyFL?

KL divergence quantifies how one probability distribution diverges from a second, expected distribution. In ProxyFL:
- **Private to Proxy**: Ensures the private model’s outputs are aligned with those of the proxy model.
- **Proxy to Private**: Encourages the proxy model to mimic the private model’s behavior.
This **bidirectional alignment** helps transfer knowledge while preserving the distinct roles of each model and avoiding data leakage.

## What is the motivation behind Federated Averaging (FedAvg) using multiple local steps before aggregation?

FedAvg allows devices to perform several local training steps before sending updates to the server. The benefits include:
- **Reduced Communication Overhead**: Fewer messages are sent, saving bandwidth.
- **Improved Local Optimization**: More accurate gradient estimation on each client.
- **Trade-off Management**: Balances computation and communication by tuning the number of local epochs.
This is particularly useful in IoT, where communication is more costly than local computation.

## How does the FedZero framework integrate power-awareness into FL?

FedZero integrates power-awareness through:
- **Client Self-Declaration**: Devices report compute capabilities and renewable energy forecasts.
- **Power Domains**: Devices are grouped based on energy availability.
- **Scheduling Algorithm**: Selects the most suitable clients to maximize training efficiency within energy limits.
- **Blacklist Strategy**: Prevents repeated selection of the same devices to ensure fairness.
This framework reduces carbon emissions and optimizes FL for green computing environments.

## What are the key assumptions of the 6LoWPAN adaptation layer that support its header compression?

6LoWPAN header compression assumes:
- **Shared Contexts**: Devices share common network settings, such as prefixes or routing paths.
- **Deterministic Structures**: Many header fields have predictable or default values.
- **Cross-layer Awareness**: Fields like addresses or hop limits can be inferred from the MAC layer.
This enables significant compression (e.g., reducing a 40-byte IPv6 header to as little as 5 bytes), making IP viable for low-power IoT networks.

## Why is the use of a proxy model essential in ProxyFL, and how does it differ from the private model?

The proxy model:
- **Is Publicly Shared**: Sent to other peers in the FL network.
- **Trained with DP Mechanisms**: Includes noise and gradient clipping.
- **Used for Collaboration**: Helps align and refine the private model without sharing raw data.

In contrast, the private model:
- **Remains Local**: Never transmitted outside the device.
- **Handles Inference**: Trained more robustly on the device’s real data.
This separation ensures strong privacy guarantees while still benefiting from collaborative learning.

## How does FedAvg handle the problem of non-IID data among clients?

Non-IID (non-independent and identically distributed) data is a major challenge in FL, as each client may have data from different distributions. FedAvg handles this by:
- **Aggregating Updates**: Weighs updates by the size of local datasets, helping balance contributions.
- **Multiple Rounds**: Iteratively aggregates updates to gradually reduce bias.
- **Careful Learning Rate Tuning**: Helps ensure convergence despite the heterogeneity.

Nonetheless, more advanced techniques (e.g., personalization layers, clustering) may be needed for highly skewed data.

## In ProxyFL, how are model updates protected using DP-SGD?

DP-SGD (Differentially Private Stochastic Gradient Descent) includes:
- **Gradient Clipping**: Limits the norm of individual gradients to bound sensitivity.
- **Noise Addition**: Adds Gaussian noise to gradients before updating the proxy model.
- **Privacy Budget Accounting**: Keeps track of total privacy loss over training rounds using (ε, δ) values.

These mechanisms ensure that the shared proxy model parameters do not reveal sensitive information about the training data.
