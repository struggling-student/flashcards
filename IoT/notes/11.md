# IoT Wireless MAC & Power-Saving Techniques

## Why is collision **detection** effective on wired Ethernet but not on most wireless links?
On copper Ethernet every station hears the same voltage on the cable, so a sender can measure the line while transmitting: the moment the voltage deviates it knows a collision happened and can abort (CSMA/**CD**).  
In WLANs the signal from a remote node is already attenuated ~70 dB by the time it reaches another transmitter; that weak echo is hidden under the glare of the sender’s own power-amp output, so the radio cannot sense the overlap. Add in “hidden nodes” that are out of one another’s range and you get collisions the transmitters never perceive, making CSMA/CD impractical.

## What is the **hidden-node problem** and how does it impair CSMA?
Two stations (A and C) that do **not** hear each other both sense an idle channel and transmit; their frames collide at the Access Point (B). Because A and C never detect the overlap they both assume success, wasting energy and airtime and forcing upper layers to request retransmission.

## Explain **CSMA/CA** and the extra handshake Wi-Fi adds.
Carrier Sense Multiple Access/**Collision Avoidance** makes a node defer if the medium is busy and back-off with a random timer. 802.11 adds **RTS/CTS**: a short *Request-To-Send* from the sender and a *Clear-To-Send* from the receiver. Neighbours that overhear either frame set their Network Allocation Vector (NAV) and stay quiet, guarding the data exchange and mitigating hidden-node collisions.

## List the five multiple-access MAC families introduced in the slides.
- **TDMA** – Time Division  
- **FDMA** – Frequency Division  
- **ALOHA / Slotted ALOHA** – pure random access  
- **MACA-RTS/CTS** – random access with dynamic reservation  
- **CDMA** – Code Division with orthogonal spreading codes  

## How does **TDMA** schedule uplink and downlink, and what are its trade-offs?
A coordinator sends a reference burst defining a repeating frame of time-slots. Each slot is reserved for one user; duplex can be half (split slot) or full (different bands with FDD).  
**Pros:** collision-free, very power-efficient (nodes sleep outside their slots).  
**Cons:** needs tight synchronisation, guard times waste airtime, high latency for burst traffic.

## Contrast **FDMA** with TDMA.
FDMA cuts the spectrum into guard-band-separated sub-bands that users occupy continuously.  
+ Low latency, no synchronisation.  
– Fixed bandwidth per user (wasteful for idle/bursty senders), hardware needs sharp RF filters, total users limited by spectrum width.

## Classical ALOHA vs **Slotted ALOHA**: what changed and what stayed the same?
Slotted ALOHA synchronises all nodes to slot boundaries so a frame can collide only with one that starts in the *same* slot, doubling maximum throughput from 18 % to 37 % of channel capacity—yet it is still random access with no carrier sense, so collisions and exponential back-off remain.

## Define **DAMA / Reservation ALOHA**.
*Demand-Assigned Multiple Access* keeps ALOHA for a short contention phase where stations request slots; a satellite (or other hub) issues a reservation map for the upcoming frame so the actual data phase is collision-free.

## Describe the **MACA** handshake and why it solves the hidden-node issue.
1. Sender broadcasts **RTS** with its ID and intended receiver.  
2. If idle, the receiver answers **CTS**; everyone that hears CTS (including hidden nodes relative to the sender) stays silent for the announced *NAV* duration.  
3. Data frame and **ACK** follow.  
Because both potential interferers near the sender (hear RTS) and those near the receiver (hear CTS) defer, collisions are greatly reduced.

## Energy waste sources in Wireless Sensor Networks (WSNs).
1. **Collisions** → retransmissions  
2. **Overhearing** packets for others  
3. **Idle listening** while the channel is empty  
4. **Control overhead** for beacons/handshakes  

## What is the philosophy behind **power-saving MAC algorithms** for IoT?
Duty-cycle the radio aggressively—sleep whenever no useful frames are expected—yet still guarantee that a sender and its receiver are simultaneously awake often enough for the application’s latency bounds.

### Non-Beacon Tracking (NBT)
Each node wakes up *asynchronously* on its own schedule, emits a short beacon then listens briefly. A sender that has data stays awake until it hears the destination’s beacon, then transmits. Average wait ≈ beacon interval / 2; no global sync required.

### Beacon Tracking (BT)
A **coordinator** defines a TDMA-like frame: common beacon + advertised sleep/active window shared by all nodes. They wake in lock-step, so rendezvous is deterministic and latency low, but clock drift and the single point of failure are challenges.  
*Multi-hop BT* builds a tree of secondary beacons so children track their parent’s schedule.

### Long Preamble Emulation (LPE / B-MAC)
Nodes sample the channel every *tᵢ*. A sender transmits a **long preamble** (or repeated short strobes) that spans at least tᵢ so the receiver’s sampling window collides with it; after detection the real data follows. Entirely asynchronous, but the preamble wastes airtime and energy at the sender.

## In BT, why do frames contain a **guard time**, and what happens if clocks drift?
Guard time absorbs propagation delay and crystal-oscillator drift so a late-arriving transmission does not spill into the neighbour’s slot. If drift exceeds the guard the nodes miss each other’s active window, so implementations either shorten the sleep or insert periodic re-synchronisation beacons.

## Explain how the **hidden-node** and **exposed-node** problems are opposites.
*Hidden*: two nodes can’t sense each other → simultaneous transmissions collide at the AP.  
*Exposed*: a node defers because it hears a frame from a neighbour even though its own receiver is out of range of that transmission, wasting throughput. Proper RTS/CTS timing and directional antennas can alleviate both.

## What properties make **CDMA** attractive and why isn’t it common in ad-hoc IoT nets?
Orthogonal spreading codes let all users share the whole band simultaneously, offer interference resistance and a measure of secrecy. But every peer in an ad-hoc mesh would need mixers and correlators for *all* active codes—costly in silicon and power—so CDMA is used mainly in centrally-coordinated cellular links.

## Compare **TDMA vs FDMA** for low-power sensor motes.
TDMA lets a node power-down its radio for > 90 % of the frame, yielding long battery life, but needs clock sync and scales poorly when the active slot is shorter than startup time.  
FDMA offers constant low-latency access and simple receivers, but nodes must stay on (or retune) to guard their narrow channel, so standby energy is higher.

## List four **wireless network categories** and their MAC challenges.
*Wi-Fi LAN* – contention & hidden nodes  
*Cellular* – centralised scheduling, plentiful power at base-station  
*MANET* – mobility, dynamic routing tables  
*WSN* – ultra-low power, collision avoidance, sleep scheduling  

## Enumerate the **major activities that drain battery** in a sensing mote and the MAC features that mitigate each.
Activity | Mitigation  
---|---  
Collision re-tx | deterministic slots (TDMA), RTS/CTS  
Overhearing | address filtering, LPE preamble sampling  
Idle listening | long sleep intervals, duty-cycled radios  
Control frames | piggy-back control, compress beacons  

## Why can adding more Wi-Fi Access Points without channel planning **reduce** total throughput?
Each AP’s carrier interferes with neighbours on the same or overlapping channels; clients back-off more often, so airtime per AP shrinks. Better is to colour APs with non-overlapping channels (graph-colouring problem) or exploit higher attenuation walls to isolate cells.

## Briefly explain **graph colouring** as applied to Wi-Fi channel assignment.
Model APs as vertices; draw an edge if two are within interference range. Assign a “colour” (channel) so adjacent vertices differ. Minimising colours (chromatic number) or overlap weight is NP-hard, but greedy heuristics give practical layouts with less co-channel interference.

## What’s the principle behind choosing 60 GHz for short-range high-density links?
Atmospheric oxygen has an absorption peak near 60 GHz, so signals attenuate in tens of metres. The rapid decay confines interference to one room, enabling many spatial re-uses of the same spectrum, perfect for gigabit WLANs like IEEE 802.11ad/ay.

## Given the huge free-space loss, how do IoT radios reach kilometres on coin-cell power?
They combine:  
* Narrowband modulation (FSK, LoRa CSS) for processing gain  
* High-gain directional or elevated antennas at gateways  
* Low data-rate → longer symbol time → better receiver sensitivity  
* Duty-cycled transmissions under regional power limits.

## Summarise the **trade-off triangle** of MAC design for IoT.
You juggle **energy**, **latency**, and **throughput**. More frequent beacons or carrier sensing lowers latency but raises listening cost; TDMA slots cut collisions and save energy but create delay; higher-order modulations raise throughput yet need stronger SNR → more transmit power.
